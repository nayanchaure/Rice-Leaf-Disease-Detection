{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKOhV2oWzysW",
        "outputId": "2f32197d-b148-4789-e877-1283ebf16d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 28 20:04:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QK7qwZVI9Hdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f64647-c67f-4952-99bc-a09a4f1f5ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "t3UqeVHE9Y-j",
        "outputId": "0f27d820-22d3-4082-b026-674ced60d739",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "73XhFMB19cLI",
        "outputId": "5456954c-694d-464b-d28b-cac8a9056d61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npEc1R-s9fRn",
        "outputId": "4ead067a-db55-4a49-ece8-e61bb5dba961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download -d shayanriyaz/riceleafs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PxwnvftM-aUE",
        "outputId": "8129db60-3070-4fa9-91ad-77b2d255b506",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/riceleafs.zip, /content/riceleafs.zip.zip or /content/riceleafs.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/riceleafs.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqc9l_pr-r2y"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6R4k-8Hi-juD",
        "outputId": "046c2324-12e2-4049-d30f-2454551252dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-68299c812bc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     batch_size=64)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m       \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m           \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/RiceLeafs/train'"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "IMG_SHAPE=(224,224)\n",
        "BATCH_SIZE=32\n",
        "\n",
        "train_dir=\"/content/RiceLeafs/train\"\n",
        "test_dir=\"/content/RiceLeafs/validation\"\n",
        "\n",
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode=\"nearest\")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, \n",
        "    subset=\"training\", \n",
        "    shuffle=True, \n",
        "    seed=42,\n",
        "    color_mode=\"rgb\", \n",
        "    class_mode=\"categorical\",\n",
        "    target_size=IMG_SHAPE,\n",
        "    batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "imr1omsY0cEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elhSKR3q_ioB"
      },
      "outputs": [],
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir, \n",
        "    shuffle=False, \n",
        "    seed=42,\n",
        "    color_mode=\"rgb\",     \n",
        "    class_mode=\"categorical\",\n",
        "    target_size=IMG_SHAPE,\n",
        "    batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is7uRw4-CX8w"
      },
      "source": [
        "# Building Model\n",
        "### Functional API Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ioex_DbzCWkR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "#input layer\n",
        "inputs=tf.keras.layers.Input(shape=(224,224,3))\n",
        "x=feature_vectorizer(inputs) #2d \n",
        "x=tf.keras.layers.Flatten()(x) #1d\n",
        "\n",
        "#Hidden layer\n",
        "x=tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x=tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x=tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "\n",
        "x=tf.keras.layers.Dropout(0.2)(x) #avoids overfitting\n",
        "\n",
        "#Output layer\n",
        "outputs=tf.keras.layers.Dense(train_generator.num_classes,activation=\"softmax\")(x)\n",
        "\n",
        "#Model setting\n",
        "model1=tf.keras.Model(inputs,outputs)\n",
        "model1.summary()\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(loss=\"categorical_crossentropy\",\n",
        "               optimizer=\"adam\",\n",
        "               metrics=[\"accuracy\"])\n",
        "\n",
        "# Fitting the model\n",
        "model1.fit(train_generator,\n",
        "           epochs=5 ,                 #Epochs\n",
        "           steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
        "           validation_data=test_generator,\n",
        "           validation_steps=test_generator.samples//test_generator.batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "9aSr2qu7UCng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "J0qdgtNmUDFA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_qyXJMYDjGC"
      },
      "outputs": [],
      "source": [
        "#imagenet feature vectorizer\n",
        "import tensorflow_hub as hub\n",
        "feature_vectorizer = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\",\n",
        "                                   input_shape=IMG_SHAPE+(3,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76C_KuayD4Tl"
      },
      "source": [
        "# Image Loading and Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpkEJYHSkZLv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlOyivXXDw95"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import io\n",
        "def load_and_prep(filename,img_shape=224,scale=False):\n",
        "  # reading the image\n",
        "  img=tf.io.read_file(filename)\n",
        "\n",
        "  # Decode the image into tensors\n",
        "  img=tf.image.decode_image(img)\n",
        "\n",
        "  # Resize the image \n",
        "  img=tf.image.resize(img,[img_shape,img_shape])\n",
        "\n",
        "  # Scale yes/no?\n",
        "  img=img/255.\n",
        " \n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw19h7QLEDai"
      },
      "outputs": [],
      "source": [
        "class_names=[\"BrownSpot\",\"Healthy\",\"Hispa\",\"LeafBlast\"]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def pred_and_plot(model,filename,class_names=class_names):\n",
        "  # Import the target image and preprocess it.\n",
        "  img=load_and_prep(filename)\n",
        "\n",
        "  # Make predictions \n",
        "  pred=model.predict(tf.expand_dims(img,axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  pred_class=class_names[int(np.argmax(pred))]\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"prediction: {pred_class}\")\n",
        "  plt.axis(False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eM4LKRZP8QZ"
      },
      "outputs": [],
      "source": [
        "pred_and_plot(model1,\"/content/rli1.jpg\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}